{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: CKY Algorithm and Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: CKY Algorithm (30 points)\n",
    "\n",
    "In this section, you will implement the CKY algorithm for an unweighted CFG. See the starter code [cky.py](http://people.cs.umass.edu/~brenocon/inlp2017/hw4/cky.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.1 (8 points)\n",
    "Implement the acceptance version of CKY as ``cky_acceptance()``, which returns True if there is a ``S`` covering the entire sentence. Does it return True or False for the following sentences? Please ``pprint()`` the chart cells for each case as well. \n",
    "* the the\n",
    "* the table attacked a dog\n",
    "* the cat\n",
    "\n",
    "Hint: A simple way to implement the chart cells is by maintaining a list of nonterminals at the span. This list represents all possible nonterminals over that span. \n",
    "\n",
    "Hint: ``pprint()``ing the CKY chart cells may be useful for debugging.\n",
    "\n",
    "Hint: Python dictionaries allow tuples as keys. For example, ``d={}; d[(3,4)] = []``. A slight shortcut is that ``d[3,4]`` means the same thing as ``d[(3,4)]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar rules in tuple form:\n",
      "[('S', ('NP', 'VP')),\n",
      " ('NP', ('Det', 'Noun')),\n",
      " ('VP', ('Verb', 'NP')),\n",
      " ('PP', ('Prep', 'NP')),\n",
      " ('NP', ('NP', 'PP')),\n",
      " ('VP', ('VP', 'PP'))]\n",
      "Rule parents indexed by children:\n",
      "defaultdict(<type 'list'>, {('NP', 'VP'): ['S'], ('VP', 'PP'): ['VP'], ('Verb', 'NP'): ['VP'], ('Det', 'Noun'): ['NP'], ('NP', 'PP'): ['NP'], ('Prep', 'NP'): ['PP']})\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 4) # set default size of plots\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cky\n",
    "from pprint import pprint\n",
    "print \"Grammar rules in tuple form:\"\n",
    "pprint(cky.grammar_rules)\n",
    "print \"Rule parents indexed by children:\"\n",
    "pprint(cky.possible_parents_for_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the\n",
      "tags {'the': 'Det'}\n",
      "defaultdict(<type 'list'>, {(0, 1): ['Det'], (1, 2): ['Det'], (0, 2): []})\n",
      "False\n",
      "the table attacked a dog\n",
      "tags {'a': 'Det', 'table': 'Noun', 'the': 'Det', 'dog': 'Noun', 'attacked': 'Verb'}\n",
      "defaultdict(<type 'list'>, {(0, 1): ['Det'], (1, 2): ['Noun'], (2, 5): ['VP'], (1, 3): [' '], (4, 5): ['Noun'], (1, 4): [' '], (2, 4): [' '], (1, 5): [' '], (0, 5): ['S'], (0, 4): [' '], (2, 3): ['Verb'], (0, 3): [' '], (3, 4): ['Det'], (0, 2): ['NP'], (3, 5): ['NP']})\n",
      "True\n",
      "the cat\n",
      "tags {'the': 'Det', 'cat': 'Noun'}\n",
      "defaultdict(<type 'list'>, {(0, 1): ['Det'], (1, 2): ['Noun'], (0, 2): ['NP']})\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Print the result here\n",
    "import cky;reload(cky)\n",
    "print \"the the\"\n",
    "print cky.cky_acceptance([\"the\", \"the\"])\n",
    "print \"the table attacked a dog\"\n",
    "print cky.cky_acceptance([\"the\", \"table\", \"attacked\", \"a\", \"dog\"])\n",
    "print \"the cat\"\n",
    "print cky.cky_acceptance([\"the\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Question 1.2 (15 points)\n",
    "Implement the parsing version of CKY, which returns one of the legal parses for the sentence (and returns None if there are none). If there are multiple real parses, we don’t care which one you print. Implement this as `cky_parse()`. You probably want to start by copying your `cky_acceptance()` answer and modifying it. Have it return the parse in the following format, using nested lists to represent the tree (this is a simple Python variant of the Lisp-style S-expression that’s usually used for this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "['S',\n",
    "        [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
    "         ['VP', [['Verb', 'attacked'], \n",
    "                 ['NP', [['Det', 'the'], ['Noun', 'food']]]]]]]\n",
    "                 ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the parses for the following sentences.  \n",
    "* the cat saw a dog\n",
    "* the cat saw a dog in a table\n",
    "* the cat with a table attacked the food  \n",
    "\n",
    "Hint: In the chart cells, you will now have to store backpointers as well. One way to do it is to store a list of tuples, each of which is  ``(nonterminal, splitpoint, leftchild nonterm, rightchild nonterm)``. For example, if the state ``('NP', 3, 'Det', 'Noun')`` is in the cell for span (2,4), that means this is a chart state of symbol NP, which came from a ``Det`` at position (2,3) and a Noun at position (3,4).\n",
    "\n",
    "Hint: It may be useful to use a recursive function for the backtrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "  ['VP', [['Verb', 'saw'], ['NP', [['Det', 'a'], ['Noun', 'dog']]]]]]]\n",
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "  ['VP',\n",
      "   [['VP', [['Verb', 'saw'], ['NP', [['Det', 'a'], ['Noun', 'dog']]]]],\n",
      "    ['PP', [['Prep', 'in'], ['NP', [['Det', 'a'], ['Noun', 'table']]]]]]]]]\n",
      "['S',\n",
      " [['NP',\n",
      "   [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "    ['PP', [['Prep', 'with'], ['NP', [['Det', 'a'], ['Noun', 'table']]]]]]],\n",
      "  ['VP', [['Verb', 'attacked'], ['NP', [['Det', 'the'], ['Noun', 'food']]]]]]]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the three sentence\n",
    "\n",
    "pprint( cky.cky_parse([\"the\", \"cat\", \"saw\", \"a\", \"dog\"]))\n",
    "pprint( cky.cky_parse([\"the\", \"cat\", \"saw\", \"a\", \"dog\",\"in\",\"a\",\"table\"]))\n",
    "pprint( cky.cky_parse(['the','cat','with','a','table','attacked','the','food']) )\n",
    "print \"*\" * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.3 (7 points)\n",
    "Revise the grammar as follows.\n",
    "\n",
    "* Add four words to the lexicon: two verbs “attack” and “attacks”, and the nouns “cats” and “dogs”.\n",
    "* Revise the rules to enforce subject-verb agreement on number.\n",
    "\n",
    "The new grammar should accept and reject the following sentences. Please run your parser on these sentences and report the parse trees for the accepted ones. Also, describe how you changed the grammar, and why.\n",
    "\n",
    "ACCEPT: ``the cat attacks the dog``   \n",
    "REJECT: ``the cat attack the dog``  \n",
    "ACCEPT: ``the cats attack the dog``  \n",
    "REJECT: ``the cat with the food on a dog attack the dog``\n",
    "\n",
    "Hint: you will need to introduce new nonterminal symbols, and modify the currently existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'attacks', 'the', 'dog']\n",
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "  ['VP', [['Verb', 'attacks'], ['NP', [['Det', 'the'], ['Noun', 'dog']]]]]]]\n",
      "['the', 'cat', 'attack', 'the', 'dog']\n",
      "None\n",
      "['the', 'cats', 'attack', 'the', 'dog']\n",
      "['S',\n",
      " [['NPS', [['Det', 'the'], ['NounS', 'cats']]],\n",
      "  ['VPS', [['VerbS', 'attack'], ['NP', [['Det', 'the'], ['Noun', 'dog']]]]]]]\n",
      "['the', 'cat', 'with', 'the', 'food', 'on', 'a', 'dog', 'attack', 'the', 'dog']\n",
      "None\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the four sentence\n",
    "print ['the','cat','attacks','the','dog']\n",
    "pprint( cky.cky_parse(['the','cat','attacks','the','dog']) )\n",
    "\n",
    "print ['the', 'cat', 'attack', 'the', 'dog']\n",
    "pprint( cky.cky_parse(['the', 'cat', 'attack', 'the', 'dog']) )\n",
    "\n",
    "print ['the', 'cats', 'attack', 'the', 'dog']\n",
    "pprint( cky.cky_parse(['the', 'cats', 'attack', 'the', 'dog']) )\n",
    "\n",
    "print ['the', 'cat', 'with', 'the', 'food', 'on', 'a', 'dog', 'attack', 'the', 'dog']\n",
    "pprint( cky.cky_parse(['the', 'cat', 'with', 'the', 'food', 'on', 'a', 'dog', 'attack', 'the', 'dog']) )\n",
    "print \"*\" * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Updated Grammar:-\n",
    "    \n",
    "grammar_text = \"\"\"\n",
    "S -> NP VP\n",
    "S -> NPS VPS  #----------New Rule\n",
    "NP -> Det Noun\n",
    "NPS -> Det NounS  #-------------New Rule\n",
    "VP -> Verb NP\n",
    "VPS -> VerbS NP  #--------------New rule\n",
    "PP -> Prep NP\n",
    "NP -> NP PP\n",
    "VP -> VP PP\n",
    "\"\"\"\n",
    "\n",
    "lexicon = {\n",
    "    'Noun': set(['cat', 'dog', 'table', 'food']),\n",
    "    'NounS': set(['dogs', 'cats']),\n",
    "    'Verb': set(['attacked', 'saw', 'loved', 'hated', 'attacks']),\n",
    "    'VerbS': set(['attack']),\n",
    "    'Prep': set(['in', 'of', 'on', 'with']),\n",
    "    'Det': set(['the', 'a']),\n",
    "}\n",
    "\n",
    "#I  introduced new terminal symbols NounS and VerbS to include words that are plural and introduced rules\n",
    "#that can separately handle the plural noun with the plural verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Weighted CKY Algorithm (40 points)\n",
    "In this section you will implement the weighted CKY Algorithm for a Probabilistic CFG. You will have to make modifications to the existing algorithm to account for the probabilities and your parse function should output the most probable parse tree. \n",
    "Please write all your code in ``weighted_cky.py`` file for this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.1 (7 points)\n",
    "The CKY Algorithm requires the CFG to be in Chomsky Normal Form. Convert the following CFG into Chomsky Normal Form. (For the sake of uniformity, replace the leftmost pairs of non-terminals with new non-terminal)\n",
    "\n",
    "S -> Aux NP VP   \n",
    "S -> VP  \n",
    "VP -> Verb NP  \n",
    "VP -> VP PP  \n",
    "Verb -> book  \n",
    "Aux -> does  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the unit rule (S -> VP) we get\n",
    "\n",
    "S -> Aux NP VP \n",
    "\n",
    "S -> Verb NP\n",
    "\n",
    "S -> VP PP\n",
    "\n",
    "VP -> Verb NP  \n",
    "VP -> VP PP  \n",
    "Verb -> book  \n",
    "Aux -> does  \n",
    "\n",
    "Introducing a new rule ANP -> Aux NP, we replace S -> Aux NP VP as follows:\n",
    "\n",
    "S -> ANP VP \n",
    "\n",
    "S -> Verb NP\n",
    "\n",
    "S -> VP PP\n",
    "\n",
    "VP -> Verb NP  \n",
    "VP -> VP PP  \n",
    "Verb -> book  \n",
    "Aux -> does  \n",
    "ANP -> Aux NP\n",
    "\n",
    "This is in CNF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.2 (8 points)\n",
    "We will now implement a weighted CYK algorithm to parse a sentence and return the most probable parse tree. \n",
    "The grammar is defined in ``pcfg_grammar_original.txt``. As you can notice, some of the rules are not in CNF. \n",
    "Modify the ``pcfg_grammar_modified.txt`` file such that all the rules are in Chomsky Normal Form.\n",
    "(For the sake of uniformity, replace the leftmost pairs of non-terminals with new non-terminal)\n",
    "\n",
    "Note: When transforming the grammar to CNF, must set production probabilities to preserve the probability of derivations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Question 2.3 (5 points)\n",
    "Explain briefly what are the changes you made to convert the grammar into CNF Form. Why did you make these changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "\n",
    "The modified rules are as follows:\n",
    "\n",
    "S -> ANP VP   0.8\n",
    "\n",
    "ANP -> Aux NP   1.0\n",
    "\n",
    "I replaced NP -> Pronoun with the following rules since CNF can have only one non-terminal on the left and either one terminal or two non-terminals on the right.\n",
    "\n",
    "NP -> I    0.1\n",
    "\n",
    "NP -> he    0.02\n",
    "\n",
    "NP -> she    0.02\n",
    "\n",
    "NP -> me    0.06\n",
    "\n",
    "I replaced Nominal -> Noun with the following rules since CNF can have only one non-terminal on the left and either one terminal or two non-terminals on the right.\n",
    "\n",
    "Nominal -> book  0.03\n",
    "\n",
    "Nominal -> flight  0.15\n",
    "\n",
    "Nominal -> meal  0.06\n",
    "\n",
    "Nominal -> money  0.06\n",
    "\n",
    "I replaced VP -> Verb with the following rules since CNF can have only one non-terminal on the left and either one terminal or two non-terminals on the right.\n",
    "\n",
    "VP -> book   0.1\n",
    "\n",
    "VP -> include   0.04\n",
    "\n",
    "VP -> prefer   0.06\n",
    "\n",
    "Noun -> book 0.1\n",
    "\n",
    "Noun -> flight   0.5\n",
    "\n",
    "Noun -> meal 0.2\n",
    "\n",
    "Noun -> money    0.2\n",
    "\n",
    "Also the sum of the probabilities of the broken rules is equal to the probability of the rule being broken, which satisfies the constraint that the sum of probabilities of a non-terminal should be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.4 (8 points)\n",
    "Complete the ``populate_grammar_rules()`` function in the ``weighted_cky.py`` script. This function will have to read in the grammar rules from ``pcfg_grammar_modified.txt`` file and populate the `grammar_rules` and `lexicon` data structure. Additionally you would need to store the probability mapping in a suitable data structure. \n",
    "\n",
    "Hint: You can modify the starter code provided in cky.py for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar rules in tuple form:\n",
      "[('S', ('NP', 'VP')),\n",
      " ('S', ('ANP', 'VP')),\n",
      " ('S', ('Verb', 'NP')),\n",
      " ('S', ('VP', 'PP')),\n",
      " ('ANP', ('Aux', 'NP')),\n",
      " ('NP', ('Det', 'Nominal')),\n",
      " ('Nominal', ('Nominal', 'Noun')),\n",
      " ('Nominal', ('Nominal', 'PP')),\n",
      " ('VP', ('Verb', 'NP')),\n",
      " ('VP', ('VP', 'PP')),\n",
      " ('PP', ('Prep', 'NP'))]\n",
      "Rule parents indexed by children:\n",
      "defaultdict(<type 'list'>, {('Aux', 'NP'): ['ANP'], ('NP', 'VP'): ['S'], ('Nominal', 'Noun'): ['Nominal'], ('VP', 'PP'): ['S', 'VP'], ('Det', 'Nominal'): ['NP'], ('Verb', 'NP'): ['S', 'VP'], ('Nominal', 'PP'): ['Nominal'], ('Prep', 'NP'): ['PP'], ('ANP', 'VP'): ['S']})\n",
      "probabilities\n",
      "{('ANP', ('Aux', 'NP')): '1.0',\n",
      " ('Aux', 'does'): '1.0',\n",
      " ('Det', 'a'): '0.2',\n",
      " ('Det', 'that'): '0.1',\n",
      " ('Det', 'the'): '0.6',\n",
      " ('Det', 'this'): '0.1',\n",
      " ('NP', 'Houston'): '0.16',\n",
      " ('NP', 'I'): '0.1',\n",
      " ('NP', 'NWA'): '0.04',\n",
      " ('NP', 'he'): '0.02',\n",
      " ('NP', 'me'): '0.06',\n",
      " ('NP', 'she'): '0.02',\n",
      " ('NP', ('Det', 'Nominal')): '0.6',\n",
      " ('Nominal', 'book'): '0.03',\n",
      " ('Nominal', 'flight'): '0.15',\n",
      " ('Nominal', 'meal'): '0.06',\n",
      " ('Nominal', 'money'): '0.06',\n",
      " ('Nominal', ('Nominal', 'Noun')): '0.2',\n",
      " ('Nominal', ('Nominal', 'PP')): '0.5',\n",
      " ('Noun', 'book'): '0.1',\n",
      " ('Noun', 'flight'): '0.5',\n",
      " ('Noun', 'meal'): '0.2',\n",
      " ('Noun', 'money'): '0.2',\n",
      " ('PP', ('Prep', 'NP')): '1.0',\n",
      " ('Prep', 'from'): '0.25',\n",
      " ('Prep', 'near'): '0.2',\n",
      " ('Prep', 'on'): '0.1',\n",
      " ('Prep', 'through'): '0.2',\n",
      " ('Prep', 'to'): '0.25',\n",
      " ('Pronoun', 'I'): '0.5',\n",
      " ('Pronoun', 'he'): '0.1',\n",
      " ('Pronoun', 'me'): '0.3',\n",
      " ('Pronoun', 'she'): '0.1',\n",
      " ('Proper-Noun', 'Houston'): '0.8',\n",
      " ('Proper-Noun', 'NWA'): '0.2',\n",
      " ('S', ('ANP', 'VP')): '0.1',\n",
      " ('S', ('NP', 'VP')): '0.8',\n",
      " ('S', ('VP', 'PP')): '0.05',\n",
      " ('S', ('Verb', 'NP')): '0.05',\n",
      " ('VP', 'book'): '0.1',\n",
      " ('VP', 'include'): '0.04',\n",
      " ('VP', 'prefer'): '0.06',\n",
      " ('VP', ('VP', 'PP')): '0.3',\n",
      " ('VP', ('Verb', 'NP')): '0.5',\n",
      " ('Verb', 'book'): '0.5',\n",
      " ('Verb', 'include'): '0.2',\n",
      " ('Verb', 'prefer'): '0.3'}\n",
      "Lexicon\n",
      "{'Aux': set(['does']),\n",
      " 'Det': set(['a', 'that', 'the', 'this']),\n",
      " 'NP': set(['Houston', 'I', 'NWA', 'he', 'me', 'she']),\n",
      " 'Nominal': set(['book', 'flight', 'meal', 'money']),\n",
      " 'Noun': set(['book', 'flight', 'meal', 'money']),\n",
      " 'Prep': set(['from', 'near', 'on', 'through', 'to']),\n",
      " 'Pronoun': set(['I', 'he', 'me', 'she']),\n",
      " 'Proper-Noun': set(['Houston', 'NWA']),\n",
      " 'VP': set(['book', 'include', 'prefer']),\n",
      " 'Verb': set(['book', 'include', 'prefer'])}\n"
     ]
    }
   ],
   "source": [
    "from weighted_cky import populate_grammar_rules\n",
    "from weighted_cky import *\n",
    "populate_grammar_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.5 (12 points)\n",
    "Implement the weighted parsing version of CKY, which returns the most probable legal parse for the sentence (and returns None if there are none). If there are multiple real parses, this function will always return the most probable parse i.e the one with maximum probability. \n",
    "Complete the ``pcky_parse()``.\n",
    "Print the parse tree and the probabilities for the following sentences:\n",
    "* book the flight through Houston\n",
    "* include this book\n",
    "* the the\n",
    "\n",
    "Hint: You can use the code in `cky_parse()` and modify it to accomodate probabilities and compute the most probable parse.   \n",
    "Note: The topmost cell should contain rules associated with the `S` non terminal, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the']\n",
      "cells before updating via cky\n",
      "defaultdict(<type 'float'>, {(1, 2, 'Det'): '0.6', (0, 1, 'Det'): '0.6'})\n",
      "backpointers\n",
      "defaultdict(<type 'list'>, {})\n",
      "'REJECT'\n",
      "\n",
      "\n",
      "\n",
      "['book', 'the', 'flight', 'through', 'Houston']\n",
      "cells before updating via cky\n",
      "defaultdict(<type 'float'>, {(3, 4, 'Prep'): '0.2', (2, 3, 'Nominal'): '0.15', (0, 1, 'VP'): '0.1', (0, 1, 'Noun'): '0.1', (2, 3, 'Noun'): '0.5', (0, 1, 'Verb'): '0.5', (4, 5, 'Proper-Noun'): '0.8', (4, 5, 'NP'): '0.16', (1, 2, 'Det'): '0.6', (0, 1, 'Nominal'): '0.03'})\n",
      "backpointers\n",
      "defaultdict(<type 'list'>, {(0, 5, 'VP'): [(0, 1, 'Verb'), (1, 5, 'NP')], (0, 3, 'S'): [(0, 1, 'Verb'), (1, 3, 'NP')], (2, 5, 'Nominal'): [(2, 3, 'Nominal'), (3, 5, 'PP')], (0, 5, 'S'): [(0, 3, 'VP'), (3, 5, 'PP')], (1, 5, 'NP'): [(1, 2, 'Det'), (2, 5, 'Nominal')], (0, 3, 'VP'): [(0, 1, 'Verb'), (1, 3, 'NP')], (3, 5, 'PP'): [(3, 4, 'Prep'), (4, 5, 'NP')], (1, 3, 'NP'): [(1, 2, 'Det'), (2, 3, 'Nominal')]})\n",
      "['S',\n",
      " 2.1600000000000003e-05,\n",
      " [['VP',\n",
      "   0.0135,\n",
      "   [['Verb', 'book', '0.5'],\n",
      "    ['NP', 0.054, [['Det', 'the', '0.6'], ['Nominal', 'flight', '0.15']]]]],\n",
      "  ['PP', 0.032, [['Prep', 'through', '0.2'], ['NP', 'Houston', '0.16']]]]]\n",
      "\n",
      "\n",
      "\n",
      "['include', 'this', 'book']\n",
      "cells before updating via cky\n",
      "defaultdict(<type 'float'>, {(2, 3, 'Nominal'): '0.03', (2, 3, 'VP'): '0.1', (0, 1, 'VP'): '0.04', (2, 3, 'Noun'): '0.1', (2, 3, 'Verb'): '0.5', (1, 2, 'Det'): '0.1', (0, 1, 'Verb'): '0.2'})\n",
      "backpointers\n",
      "defaultdict(<type 'list'>, {(0, 3, 'VP'): [(0, 1, 'Verb'), (1, 3, 'NP')], (0, 3, 'S'): [(0, 1, 'Verb'), (1, 3, 'NP')], (1, 3, 'NP'): [(1, 2, 'Det'), (2, 3, 'Nominal')]})\n",
      "['S',\n",
      " 1.8000000000000004e-05,\n",
      " [['Verb', 'include', '0.2'],\n",
      "  ['NP', 0.0018, [['Det', 'this', '0.1'], ['Nominal', 'book', '0.03']]]]]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from weighted_cky import pcky_parse\n",
    "from weighted_cky import *\n",
    "\n",
    "populate_grammar_rules()\n",
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the three sentence\n",
    "print ['the','the']\n",
    "pprint( pcky_parse(['the','the']) )\n",
    "print '\\n\\n'\n",
    "\n",
    "print ['book','the','flight','through','Houston']\n",
    "pprint( pcky_parse(['book','the','flight','through','Houston']) )\n",
    "print '\\n\\n'\n",
    "\n",
    "print ['include','this','book']\n",
    "pprint(pcky_parse(['include','this','book']))\n",
    "print \"*\" * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Dependency parser output (30 points)\n",
    "\n",
    "You will conduct manual error analysis of [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)'s dependency parser.\n",
    "\n",
    "Create an English sentence where the parser makes an error, and you know what the correct analysis ought to be, according to the Universal Dependencies grammatical standard.  You will want to play around with different sentences, look at their output, and check against the Universal Dependencies annotation standard.  The current version of CoreNLP outputs according to the \"UD version 1\" standard, so please use this page:\n",
    " * [UD v1 homepage](http://universaldependencies.org/docsv1/)\n",
    " * and in particular, the [UD v1 dependency relations list](http://universaldependencies.org/docsv1/u/dep/index.html)\n",
    "\n",
    "For quickly looking at things, their [online demo](http://corenlp.run/) may be useful.\n",
    "\n",
    "However, for this assignment, you need to run the parser to output in \"conllu\" format, which is human readable.  You need to download and run the parser for this.  (It requires Java.) Use version 3.8.0 (it should be the current version). You can it working in interactive mode so you can just type sentences into it on the terminal like this:\n",
    "\n",
    "```\n",
    "./corenlp.sh -annotators tokenize,ssplit,pos,lemma,depparse -outputFormat conllu \n",
    "[...]\n",
    "Entering interactive shell. Type q RETURN or EOF to quit.\n",
    "NLP> \n",
    "```\n",
    "\n",
    "For example then you can type\n",
    "```\n",
    "NLP> I saw a cat.\n",
    "1       I       I       _       PRP     _       2       nsubj   _       _\n",
    "2       saw     see     _       VBD     _       0       root    _       _\n",
    "3       a       a       _       DT      _       4       det     _       _\n",
    "4       cat     cat     _       NN      _       2       dobj    _       _\n",
    "5       .       .       _       .       _       2       punct   _       _\n",
    "```\n",
    "\n",
    "You can also use the `-inputFile` flag if you'd rather give it a whole file at once.\n",
    "\n",
    "As you can see in the parser documentation, the 7th and 8th columns describe the dependency edge for the word's parent (a.k.a governor): it has the index of its parent, and the edge label (a.k.a. the relation).  For example, this parse contains the dependency edge *nsubj(saw:2, I:1)* meaning that \"I\" is the subject of \"saw\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Once you've decided your sentence, please put the conllu-formatted parser output below in the markdown triple-quoted area.  Please be very careful where it goes since we will use a script to pull it out.\n",
    "    \n",
    "PARSE GOES BELOW HERE\n",
    "```\n",
    "NLP> I bank on my parents.\n",
    "1       I       I       _       PRP     _       2       nsubj   _       _\n",
    "2       bank    bank    _       NN      _       0       root    _       _\n",
    "3       on      on      _       IN      _       5       case    _       _\n",
    "4       my      my      _       PRP$    _       5       nmod:poss       _      _\n",
    "5       parents parent  _       NNS     _       2       nmod    _       _\n",
    "6       .       .       _       .       _       2       punct   _       _\n",
    "\n",
    "```\n",
    "PARSE GOES ABOVE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** Please describe the error you found.  Also give a citation and link to the relevant part of the UD documentation describing one of the relations that the parser predicted in error, or did something wrong with.\n",
    "\n",
    "'bank' has been mistakenly identified as NN but it should be 'VB'. Here, the dependency 'nsubj' is incorrect. This is because\n",
    "\n",
    "\"the governor of the nsubj relation might not always be a verb: when the verb is a copular verb, the root of the clause is the complement of the copular verb, which can be an adjective or noun, including a noun marked by a preposition\". \n",
    "\n",
    "However, here 'bank' has been identified as a Noun and it is not the complement of a copular verb. Hence the mistake.\n",
    "\n",
    "http://universaldependencies.org/docsv1/u/dep/nsubj.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 3.3:** Please give correct that error in the parse .  Put your corrected parse, again in that conllu textual format, below.  You should take a copy of the output and manually change some of the 7th/8th dependency edge columns.\n",
    "\n",
    "PARSE GOES BELOW HERE\n",
    "```\n",
    "NLP> I bank on my parents.\n",
    "1       I       I       _       PRP     _       2       nsubj   _       _\n",
    "2       bank    bank    _       VB      _       0       root    _       _\n",
    "3       on      on      _       IN      _       5       case    _       _\n",
    "4       my      my      _       PRP$    _       5       nmod:poss       _      _\n",
    "5       parents parent  _       NNS     _       2       nmod    _       _\n",
    "6       .       .       _       .       _       2       punct   _       _\n",
    "```\n",
    "PARSE GOES ABOVE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4:** Please describe your correction and why it solves the error.\n",
    "\n",
    "I have changed the POS tag for 'bank' from NN to VB. This solves the parsing problem since VB can be a governor of a pronoun(I). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
